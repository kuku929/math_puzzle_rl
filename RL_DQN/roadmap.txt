tasks:
1. implement epsilon greedy policy and test it, epsilon = 1/sqrt(n+1), n = no. of iterations..done..

2. write the struct for creating nueral network, also implement the following functions:
	-create(size_input_layer, size_of_hidden_layer, size_output_layer)->create random weights and biases..done..
	-predict(input)->output Q(s,a) value..done..
	-fit(input, Q_true_value)-> update weights using back propagation..done..	

3. create a actor struct which will have:
	-one neural network for learning..done.. 
	-experience log to randomly sample training data from..done..
	-uses epsilon greedy policy..done..

4. create a critic struct which will have:
	-one nueral network for target Q(s,a)..done..
	-copy weights of this network from actor after every n iterations.

5. create a random state initializer for training.


NOTES:
normalize the input to have mean 0 and deviation 1
functions left: Reward(R), normalize
